---
title: "R_club"
author: "Ruijuan Li"
date: "12/6/2017"
output: html_document
---

### Lab

12-06-2017 
### Linear regression 
```{r}
library(MASS)
library(ISLR)

# simple linear regression 
# fix(Boston)
names(Boston)
?Boston

lm.fit = lm(medv ~ lstat, data = Boston)
lm.fit
summary(lm.fit)

names(lm.fit)
coef(lm.fit)

confint(lm.fit)

predict(lm.fit,data.frame(lstat=c(5,10,15)), interval ="confidence")
predict(lm.fit,data.frame(lstat=c(5,10,15)), interval ="prediction") # difference between these two 

attach(Boston)
plot(lstat, medv)
abline(lm.fit)

par(mfrow=c(2,2))
plot(lm.fit)

plot(predict(lm.fit), residuals(lm.fit)) # residule 
plot(predict(lm.fit), rstudent(lm.fit)) # studendized residual, what is this? 

plot(hatvalues (lm.fit)) # what???? 
which.max(hatvalues (lm.fit))
# prediction interval VS confidence interval 
```

### 12-13-2017 Multiple linear regression 
Q I have when reading 
1) for multiple regression, what if there is repulsive interaction effect, then those predictor will not be identified, compare to scanone  CIM  and scantwo 
2) genomic prediction remove highly correlated markers similar to here
3) F-test: The test statistic in an F-test is the ratio of two scaled sums of squares reflecting different sources of variability. These sums of squares are constructed so that the statistic tends to be greater when the null hypothesis is not true. Anova() 
4) I like the confidence interval and prediction interval explanation part 
```{r}
library(MASS)
library(ISLR)
lm.fit <- lm(medv ~ lstat + age, data = Boston) 
summary(lm.fit)

# regression using all variable 
lm.fit <- lm(medv ~ ., data = Boston)
summary(lm.fit)

library(car)
vif(lm.fit) # don't understand ... look for colinearity problem 
?vif # variance inflation factor 

# regression using all but one variable 
lm.fit1 <- lm(medv ~ .-age, data = Boston)
summary(lm.fit1)

# or use update to update the variable 
lm.fit1 <- update(lm.fit, ~.-age) 
```

### 12-20-2017 interaction term, non-linear transformation of the predictors 
```{r}
attach(Boston)
summary(lm(medv ~ lstat*age,data=Boston))
lm.fit2=lm(medv ~ lstat+I(lstat^2)) 
summary(lm.fit2)

lm.fit=lm(medv~lstat)
anova(lm.fit ,lm.fit2) # variance explained by the two models, are they significantly different? F-test 
par(mfrow=c(2,2))
plot(lm.fit2)

lm.fit5=lm(medv~poly(lstat ,5)) 
summary(lm.fit5)
summary(lm(medv~log(rm),data=Boston))

# fix(Carseats)
names(Carseats)  

lm.fit=lm(Sales ~ .+Income:Advertising+Price:Age,data=Carseats)
summary(lm.fit)

attach(Carseats)
contrasts(ShelveLoc) 
```

### 01-16-2018 logistic regression 
```{r}
library(ISLR)
names(Smarket)
summary(Smarket)

cor(Smarket[,-9])
attach(Smarket)
plot(Volume)

glm.fits=glm(Direction ~ Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Smarket ,family=binomial)
summary(glm.fits)

coef(glm.fits)
summary(glm.fits)$coef

glm.probs=predict(glm.fits,type="response")
glm.probs[1:10]
length(glm.probs)

contrasts (Direction )

glm.pred=rep("Down",1250)
glm.pred[glm.probs >.5]="Up"

glm.pred

table(glm.pred,Direction)
(507+145) /1250 

mean(glm.pred==Direction)

train =( Year <2005)
Smarket.2005= Smarket [! train ,]
dim(Smarket.2005) # 252 
train %>% sum()
Direction.2005=Direction[!train]

glm.fits=glm(Direction ~ Lag1+Lag2+Lag3+Lag4+Lag5+Volume , data=Smarket ,family=binomial,subset=train)

glm.probs=predict(glm.fits,Smarket.2005,type="response")

glm.pred=rep("Down",252)
glm.pred[glm.probs >.5]="Up"
table(glm.pred,Direction.2005)

mean(glm.pred==Direction.2005)
mean(glm.pred!=Direction.2005)

(97+34)/252

glm.fits=glm(Direction~Lag1+Lag2,data=Smarket ,family=binomial, subset=train)
glm.probs=predict(glm.fits,Smarket.2005,type="response")
glm.pred=rep("Down",252)
glm.pred[glm.probs >.5]="Up"
table(glm.pred,Direction.2005)

mean(glm.pred==Direction.2005)
106/(106+76)
```

### 01-23-2018 linear discriminant analysis 
```{r}
# LDA: linear discriminant analysis 
library(MASS)
library(ISLR)
attach(Smarket)
train =Smarket$Year < 2005
Smarket.2005= Smarket [!train,]
Direction.2005=Direction[!train]

lda.fit=lda(Direction ~ Lag1+Lag2,data=Smarket, subset=train)
lda.fit

lda.pred=predict(lda.fit, Smarket.2005)
names(lda.pred)

lda.class=lda.pred$class
table(lda.class ,Direction.2005)

mean(lda.class==Direction.2005)
sum(lda.pred$posterior[,1]>=.5) 
sum(lda.pred$posterior[,1]<.5) 

lda.pred$posterior[1:20,1] 
lda.class[1:20]

sum(lda.pred$posterior[,1]>.9)  

# pi(k) = Pr(Y = k): prior probaility 
# fk(x): probability of y=k for given X=x. 

# random cross validataion: to avoid samples which have abnormal values fall into the same group
```

### 01-30-2018 QDA & KNN 
```{r}
# Qs on the text: page 150, LDA vs QDA vs KNN 
# t distribution on page 153
# correlation between predictors... ??? don't quite get it...  

library(MASS) 
library(ISLR)
attach(Smarket)
train =Smarket$Year < 2005
Smarket.2005= Smarket [!train,]
Direction.2005=Direction[!train]

### QDA 
qda.fit=qda(Direction ~ Lag1+Lag2,data=Smarket ,subset=train)
qda.fit # don't understand the summary result 

qda.class=predict(qda.fit,Smarket.2005)$class 
table(qda.class ,Direction.2005)

mean(qda.class==Direction.2005)

unique(Smarket$Year)

### KNN 
library(class)
Lag1
Lag2
train.X=cbind(Lag1 ,Lag2)[train ,] # the two P, Lag1 and Lag2, traning set 
test.X=cbind(Lag1,Lag2)[!train,] # test set
train.Direction =Direction [train] # direction for training set 
train.Direction

set.seed(1) # why set.seed() ?
knn.pred=knn(train.X,test.X,train.Direction ,k=1)
table(knn.pred,Direction.2005)

(83+43) /252

knn.pred=knn(train.X,test.X,train.Direction ,k=3)
table(knn.pred,Direction.2005)

mean(knn.pred==Direction.2005)

### An application to Caravan Insurance Data 
dim(Caravan) 
attach(Caravan)
summary(Purchase)

standardized.X=scale(Caravan [,-86]) # why scale and center expression data when include it as predictors for genomic prediction 
var ( Caravan [ ,1]) 
var ( Caravan [ ,2])
var(standardized.X[,1]) 
var(standardized.X[,2])

test =1:1000
train.X=standardized.X[-test ,]
test.X=standardized.X[test ,]
train.Y=Purchase [-test]
test.Y=Purchase [test]
set.seed (1)
knn.pred=knn(train.X,test.X,train.Y,k=1)
mean(test.Y!=knn.pred) 
mean(test.Y!="No")

table(knn.pred,test.Y) 
test.Y
knn.pred 
9/(68+9) # the fraction of individual predicted to buy insurance 

knn.pred=knn(train.X,test.X,train.Y,k=3) 
table(knn.pred,test.Y)
test.Y 
knn.pred
5/26
knn.pred=knn(train.X,test.X,train.Y,k=5)
table(knn.pred,test.Y)
test.Y 
knn.pred 
4/15

# Logestic regression  
glm.fits=glm(Purchase ~.,data=Caravan ,family=binomial, subset=-test)
glm.probs=predict(glm.fits,Caravan[test,],type="response")
glm.pred=rep("No",1000)
glm.pred[glm.probs >.5]="Yes" # need to understand these more... 
table(glm.pred,test.Y)
test.Y 
glm.pred 

glm.pred=rep("No",1000)
glm.pred[glm.probs >.25]=" Yes"
table(glm.pred,test.Y)
test.Y
glm.pred 
11/(22+11) 

### QDA handels the problem when the variance for different classes of K are different. 
### QDA handels the problem when the correlation of different P in different class of K are different   
```

### cross-validation 
```{r}
library(ISLR)

## validation set approach 
set.seed(1)
train=sample(392,196)

lm.fit=lm(mpg~horsepower ,data=Auto,subset=train)
attach(Auto)
mean((mpg~predict(lm.fit, Auto))[-train]^2) 

lm.fit2=lm(mpg~poly(horsepower ,2),data=Auto,subset=train) 
mean((mpg-predict(lm.fit2,Auto))[-train]^2)

lm.fit3=lm(mpg ~poly(horsepower ,3),data=Auto,subset=train)
mean((mpg-predict(lm.fit3,Auto))[-train]^2)

set.seed (2)
train=sample(392,196)
lm.fit=lm(mpg ~horsepower ,subset=train)

mean((mpg-predict(lm.fit,Auto))[-train]^2)
lm.fit2=lm(mpg~poly(horsepower ,2),data=Auto,subset=train) 
mean((mpg-predict(lm.fit2,Auto))[-train]^2)
lm.fit3=lm(mpg~poly(horsepower ,3),data=Auto,subset=train) 
mean((mpg-predict(lm.fit3,Auto))[-train]^2)

glm.fit=glm(mpg~horsepower ,data=Auto) 
coef(glm.fit)

lm.fit=lm(mpg~horsepower ,data=Auto) 
coef(lm.fit)

### LOOCV 
library(boot)
glm.fit=glm(mpg~horsepower ,data=Auto)
cv.err=cv.glm(Auto,glm.fit)
cv.err$delta # why two same values 

### 10 fold cross validation 
cv.error=rep(0,5) 
for (i in 1:5){
glm.fit=glm(mpg~poly(horsepower ,i),data=Auto) # different polynomial levels 
cv.error[i]=cv.glm(Auto,glm.fit)$delta[1] } # LOOCV 
cv.error

set.seed(17)
cv.error.10=rep(0,10) 
for (i in 1:10){
glm.fit=glm(mpg~poly(horsepower ,i),data=Auto) 
cv.error.10[i]=cv.glm(Auto,glm.fit,K=10)$delta[1] # 10 fold CV 
}
cv.error.10 

### glm(family="binomial") VS glm()
### bias-variance trade off... understand... 
```



